import logging

import numpy as np
import torch


def validate_args(args):
    """
    Check provided arguments and throw errors if anything is incorrect
    @param args: kwargs generated by main.py
    """

    if args.mode == "train":
        if args.embed_dim <= 0:
            raise ValueError("Embedding dimension must be positive: {ed}".format(ed=args.embed_dim))

        if args.hidden_dim <= 0:
            raise ValueError("Hidden dimension must be positive: {hd}".format(hd=args.hidden_dim))

        if args.num_layers <= 0:
            raise ValueError("Number of layers must be positive: {nl}".format(nl=args.num_layers))

        if args.dropout < 0 or args.dropout > 1:
            raise ValueError("Dropout must be between 0 and 1 inclusive: {drop}".format(drop=args.dropout))

        if args.epochs < 0:
            raise ValueError("Must train for a nonnegative number of epochs: {epochs}".format(epochs=args.epochs))

        if args.patience < 0:
            raise ValueError("Patience must be nonnegative: {patience}".format(patience=args.patience))

        if args.tolerance < 0:
            raise ValueError("Tolerance must be nonnegative: {tolerance}".format(tolerance=args.tolerance))

        if args.main_only_epochs < 0:
            raise ValueError("Must train for a nonnegative number of additional epochs: "
                             "{moe}".format(moe=args.main_only_epochs))

        if args.batch_size <= 0:
            raise ValueError("Batch size must be positive: {bs}".format(bs=args.batch_size))

        if args.lr <= 0:
            raise ValueError("Learning rate must be positive: {lr}".format(lr=args.lr))

        if args.clip_value < 0 and args.clip_value != -1:
            raise ValueError("Gradients must be clipped at a positive value (or -1 for no clipping): "
                             "{clip}".format(clip=args.clip_value))

        if args.trials < 1:
            raise ValueError("Number of optimization trials must be greater than 0: "
                             "{trials}".format(trials=args.trials))

        if args.num_restarts < 1:
            raise ValueError("Num_restarts must be greater than 0: {nr}".format(nr=args.num_restarts))

        if args.print_every <= 0:
            raise ValueError("Print_every must be positive: {pe}".format(pe=args.print_every))

        if args.save_path is None and args.save_lm:
            logging.warning("Note that you have passed the --save_lm flag without a value for --save_path. No model "
                            "will be saved.")

    elif args.mode == "predict":
        # no prediction args need to be validated
        pass
    elif args.mode == "evaluate":
        raise NotImplementedError("Evaluation not yet implemented")
    else:
        raise ValueError("Unknown subcommand: {mode}".format(mode=args.mode))


def set_random_seed(seed):
    """
    Set a random seed for all our important packages
    @param seed: an integer random seed
    """

    np.random.seed(seed)
    torch.manual_seed(seed)
